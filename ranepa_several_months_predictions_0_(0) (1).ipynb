{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from ldmm import LDMM\n",
    "from same import SAME\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from IPython.display import clear_output\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('real_data.xls', names=['Время',\\\n",
    "'Реальные располагаемые денежные доходы в % к предущему месяцу',\\\n",
    "'Реальные располагаемые денежные доходы в % к соответствующему периоду предыдущего года',\\\n",
    "'Реальные располагаемые денежные доходы база январь 1999 =100',\\\n",
    "'Реальная начисленная заработная плата одного работника в % к предыдущему месяцу',\\\n",
    "'Реальная начисленная заработная плата одного работника база январь 1999 =100'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df)[:, 1:]\n",
    "data[55:60, 0] = [99.8, 101.0, 106.1, 100.1, 130.4]\n",
    "data[55:60, 3] = [98.3, 100.9, 104.6, 101.1, 121.3]\n",
    "data[61, 3] = 102.3\n",
    "timestamps = np.arange(data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(238, 5)\n"
     ]
    }
   ],
   "source": [
    "data = data[:, [0,1,2,3,4]]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.tile(np.append(np.ones(1), np.append(np.zeros(10), np.ones(1))), 20)[:-2]\n",
    "data = data[mask==0]\n",
    "timestamps = timestamps[mask==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a time series to large-dimensional vectors\n",
    "#\n",
    "# ts -- 2-dimensional array, pepresenting a multivariate time series\n",
    "# bandwidth -- size of the bandwidth\n",
    "#\n",
    "# returns: an array of large-dimensional vectors\n",
    "\n",
    "def ts_to_vec(ts, bandwidth=8):\n",
    "    \n",
    "    vec = ts[:, :]\n",
    "    for i in range(bandwidth-1):\n",
    "        vec = np.append(vec[:-1, :ts.shape[1]], vec[1:, :], axis=1)\n",
    "        \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalized_features(Y_train, bandwidth=12):\n",
    "    \n",
    "    # construct the generalized states\n",
    "    Y_gen = ts_to_vec(Y_train, bandwidth=bandwidth)\n",
    "    # split the generalized data onto new train and test features\n",
    "    X_train = Y_gen[:-1, :]\n",
    "    X_test = Y_gen[-1, :].reshape(-1)\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localizing kernel for computation of weights\n",
    "def loc_kernel(x):\n",
    "    # Gaussian kernel\n",
    "    #return np.exp(-0.5*x**2)\n",
    "    # Epanechnikov kernel\n",
    "    return np.maximum(1 - x**2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def shifted_weighted_kNN(timestamps_train, timestamps_test, X_train, Y_train, X_test, n_neighbors, kernel=loc_kernel, lambd=0.05):\n",
    "    \n",
    "    # increments\n",
    "    n_train = Y_train.shape[0]\n",
    "    A = np.diag(np.ones(n_train), 0) - np.diag(np.ones(n_train-1), -1)\n",
    "    A[0,0] = 0\n",
    "    increments = A.dot(Y_train)\n",
    "    Y_shifted = increments + Y_train[-1]\n",
    "    #Y_shifted = Y_train\n",
    "    \n",
    "    # predictions\n",
    "    Y_pred = np.empty(Y_train.shape[1])\n",
    "    # compute distances\n",
    "    dist = np.linalg.norm(X_train - X_test, axis=1)\n",
    "    # sort distances\n",
    "    sorted_dist = np.sort(dist)\n",
    "    \n",
    "    for i in range(Y_train.shape[1]):\n",
    "        # compute weights\n",
    "        h = sorted_dist[n_neighbors[i]]\n",
    "        weights = kernel(dist / h)\n",
    "        # reweight by the time\n",
    "        weights = weights * np.exp(lambd * (timestamps_train - timestamps_test)) \n",
    "\n",
    "        # use weighted kNN for the prediction\n",
    "        Y_pred[i] = np.sum(Y_shifted[:, i] * weights) / np.sum(weights)\n",
    "    #Y_pred = (Y_shifted.transpose().dot(weights)).transpose() / np.sum(weights)\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_LDMM(timestamps_train, Y_train, timestamp_test, params, n_neighbors):\n",
    "    bandwidth, lambd, mu, h, n_iteration = params\n",
    "    #print(Y_train.shape)\n",
    "    # Construct the generalized features\n",
    "    generalized_X_train, generalized_X_test = generalized_features(Y_train, bandwidth=bandwidth)\n",
    "    \n",
    "    # Construct a manifold\n",
    "    generalized_X = np.append(generalized_X_train, generalized_X_test.reshape(1, -1), axis=0).astype(float)\n",
    "    # Normalize the numerical features\n",
    "    generalized_X = normalize(generalized_X)\n",
    "    # Find a manifold\n",
    "    Z = LDMM(generalized_X, lambd=lambd, mu=mu, h=h, n_iterations=n_iteration, b=0)\n",
    "    #n_iterations = 10\n",
    "    #neighbors_list = np.array([50 * 0.93**i for i in range(n_iterations)]).astype(int)\n",
    "    #Z = SAME(generalized_X, neighbors_list)\n",
    "    \n",
    "    #print(np.linalg.norm(Z - generalized_X))\n",
    "    #print(np.linalg.norm(generalized_X))\n",
    "    #print(np.linalg.norm(Z))\n",
    "    \n",
    "    # Define modified train and test features\n",
    "    Z_train = Z[:-1, :]\n",
    "    Z_test = Z[-1, :]\n",
    "    \n",
    "    #print(Z_train.shape, timestamps_train[bandwidth:].shape, Y_train[bandwidth:].shape)\n",
    "    predictions = shifted_weighted_kNN(timestamps_train[bandwidth:], timestamp_test,\\\n",
    "                                       Z_train, Y_train[bandwidth:], Z_test, n_neighbors=n_neighbors)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_SAME(timestamps_train, Y_train, timestamp_test, params):\n",
    "    bandwidth, tau, n_iterations, neighbors1, neighbors2, neighbors3, neighbors4, neighbors5= params\n",
    "    n_neighbors = (neighbors1, neighbors2, neighbors3, neighbors4, neighbors5)\n",
    "    #print(Y_train.shape)\n",
    "    # Construct the generalized features\n",
    "    generalized_X_train, generalized_X_test = generalized_features(Y_train, bandwidth=bandwidth)\n",
    "    \n",
    "    # Construct a manifold\n",
    "    generalized_X = np.append(generalized_X_train, generalized_X_test.reshape(1, -1), axis=0).astype(float)\n",
    "    # Normalize the numerical features\n",
    "    generalized_X = normalize(generalized_X)\n",
    "    Z = generalized_X\n",
    "\n",
    "    # Find a manifold\n",
    "    #Z = LDMM(generalized_X, lambd=10, mu=0.2 * generalized_X.shape[0] * 0.1, h=0.1, n_iterations=10, b=0)\n",
    "#     n_iterations = 10\n",
    "    neighbors_list = np.array([50 * 0.93**i for i in range(n_iterations)]).astype(int)\n",
    "    Z = SAME(generalized_X, neighbors_list, tau)\n",
    "    \n",
    "    #print(np.linalg.norm(Z - generalized_X))\n",
    "    #print(np.linalg.norm(generalized_X))\n",
    "    #print(np.linalg.norm(Z))\n",
    "    \n",
    "    # Define modified train and test features\n",
    "    Z_train = Z[:-1, :]\n",
    "    Z_test = Z[-1, :]\n",
    "    \n",
    "    #print(Z_train.shape, timestamps_train[bandwidth:].shape, Y_train[bandwidth:].shape)\n",
    "    predictions = shifted_weighted_kNN(timestamps_train[bandwidth:], timestamp_test,\\\n",
    "                                       Z_train, Y_train[bandwidth:], Z_test, n_neighbors=n_neighbors)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_knn(timestamps_train, Y_train, timestamp_test, n_neighbors, bandwidth=12):\n",
    "    \n",
    "    #print(Y_train.shape)\n",
    "    # Construct the generalized features\n",
    "    generalized_X_train, generalized_X_test = generalized_features(Y_train, bandwidth=bandwidth)\n",
    "    \n",
    "    # Construct a manifold\n",
    "    generalized_X = np.append(generalized_X_train, generalized_X_test.reshape(1, -1), axis=0).astype(float)\n",
    "    # Normalize the numerical features\n",
    "    Z = normalize(generalized_X)\n",
    "    #print(np.linalg.norm(Z - generalized_X))\n",
    "    #print(np.linalg.norm(generalized_X))\n",
    "    #print(np.linalg.norm(Z))\n",
    "    \n",
    "    # Define modified train and test features\n",
    "    Z_train = Z[:-1, :]\n",
    "    Z_test = Z[-1, :]\n",
    "    \n",
    "    #print(Z_train.shape, timestamps_train[bandwidth:].shape, Y_train[bandwidth:].shape)\n",
    "    predictions = shifted_weighted_kNN(timestamps_train[bandwidth:], timestamp_test,\\\n",
    "                                       Z_train, Y_train[bandwidth:], Z_test, n_neighbors=n_neighbors)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = ['Real disposable cash income in % \\n to the previous month', \\\n",
    "          'Real disposable cash income in % \\n to the corresponding period of the previous year', \\\n",
    "          'Real disposable cash income \\n base January 1999 = 100', \\\n",
    "          'Real accrued wages \\n of one employee in% of the previous month', \\\n",
    "          'Real accrued wages \\n one worker base January 1999 = 100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of test months\n",
    "n_test = 40\n",
    "params=(11, 7.0, 1500.0, 0.001, 7)\n",
    "params_knn = (11, 100.0, 1000.0, 1000.0, 15)\n",
    "lookfront = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "knn [0.00165557 0.00396715 0.00239861 0.00177703]\n",
      "ldmm [0.00155454 0.00241133 0.00152581 0.00142244]\n",
      "same [0.00116738 0.0018553  0.00151837 0.0016329 ]\n",
      "arima [0.00837624 0.00213298 0.00145582 0.00158337]\n",
      "knn [0.00233372 0.00534879 0.00410975 0.00357277]\n",
      "ldmm [0.00159845 0.00330324 0.00266793 0.00196078]\n",
      "same [0.00196213 0.00455778 0.0031503  0.00306884]\n",
      "arima [0.00118552 0.00305858 0.00251821 0.00269182]\n",
      "\n",
      "2\n",
      "knn [0.00176472 0.00434126 0.00303796 0.00427745]\n",
      "ldmm [0.0014592 0.0028675 0.00198019 0.0042891]\n",
      "same [0.001458 0.00245318 0.00209719 0.00394271]\n",
      "arima [0.00176388 0.00249325 0.00194276 0.00375188]\n",
      "knn [0.00170855 0.00590817 0.00411123 0.00499822]\n",
      "ldmm [0.00158091 0.00235454 0.00353042 0.00354393]\n",
      "same [0.00205441 0.00569466 0.00393462 0.00502488]\n",
      "arima [0.00117109 0.00391763 0.00250408 0.00413675]\n",
      "\n",
      "3\n",
      "knn [0.0030487  0.00709648 0.0042467  0.00584049]\n",
      "ldmm [0.00281025 0.00402681 0.00293258 0.00486037]\n",
      "same [0.00189623 0.00334985 0.00278699 0.00510701]\n",
      "arima [0.00183599 0.0031047  0.00202661 0.00488685]\n",
      "knn [0.00208025 0.00455897 0.00381167 0.00514799]\n",
      "ldmm [0.00156919 0.00295046 0.0033131  0.004102  ]\n",
      "same [0.00192457 0.00591852 0.00449751 0.00543768]\n",
      "arima [0.00111303 0.00474181 0.00220958 0.00405538]\n",
      "\n",
      "4\n",
      "knn [0.00314675 0.00723589 0.00450714 0.0060282 ]\n",
      "ldmm [0.00304857 0.00387206 0.00345893 0.00501547]\n",
      "same [0.0020379  0.00360712 0.00364615 0.00557899]\n",
      "arima [0.00199373 0.00331188 0.00212744 0.00518051]\n",
      "knn [0.00254021 0.00566154 0.00583087 0.00440425]\n",
      "ldmm [0.00232373 0.00396541 0.00453497 0.00412238]\n",
      "same [0.00399955 0.00788308 0.00628819 0.00627232]\n",
      "arima [0.00165353 0.00538873 0.00095906 0.00416455]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# losses_knn  = []   \n",
    "# losses_ldmm  = []  \n",
    "# (3, 1.0, 21, )\n",
    "nn = [5, 60, 10, 7, 7]\n",
    "nn_same = [3, 9, 21, 21, 15]\n",
    "nn_knn = [30, 5, 30, 30, 30]\n",
    "losses = []\n",
    "for lookfront in [1,2,3,4]:\n",
    "# for j, params in enumerate(itertools.product(bandwidths, lambdas, mus, hs, n_iterations)):\n",
    "    predictions_knn  = np.empty((n_test, lookfront, 5))\n",
    "    predictions_ldmm  = np.empty((n_test, lookfront, 5))\n",
    "    predictions_same  = np.empty((n_test, lookfront, 5))\n",
    "    predictions_arima  = np.empty((n_test, lookfront, 5))\n",
    "\n",
    "    outcomes = np.empty((n_test, lookfront, 5))\n",
    "    for i in range(n_test):\n",
    "\n",
    "        Y_train_knn = data[:-n_test+i+1-lookfront, :]\n",
    "        Y_train_ldmm = data[:-n_test+i+1-lookfront, :]\n",
    "        Y_train_same = data[:-n_test+i+1-lookfront, :]\n",
    "        Y_train_arima = data[:-n_test+i+1-lookfront, :]\n",
    "\n",
    "        for k in range(lookfront):\n",
    "            timestamps_train = timestamps[:-n_test+i+1-lookfront+k]\n",
    "            timestamp_test = timestamps[-n_test+i+1-lookfront+k]\n",
    "            Y_test = data[-n_test+i+1-lookfront+k, :]\n",
    "\n",
    "            predictions_knn[i, k, :] = predict_knn(timestamps_train, Y_train_ldmm, timestamp_test, params_knn, n_neighbors=nn_knn)[:]#predict_knn(timestamps_train, Y_train_knn, timestamp_test, n_neighbors=nn)[:]\n",
    "            predictions_ldmm[i, k, :] = predict_LDMM(timestamps_train, Y_train_ldmm, timestamp_test, params, n_neighbors=nn)[:]\n",
    "            predictions_same[i, k, :] = predict_SAME(timestamps_train, Y_train_same, timestamp_test, (3, 1.0, 21,*nn_same))[:]\n",
    "            for t in range(5):\n",
    "#                 if t == 0:\n",
    "#                     predictions_arima[i, k, t] = ARIMA(Y_train_arima[:, t], order=(6,2,0)).fit(disp=0, trend='nc').forecast(steps=1)[0]\n",
    "                predictions_arima[i, k, t] = ARIMA(Y_train_arima[:, t], order=(6,1,0)).fit(disp=0, trend='nc').forecast(steps=1)[0]\n",
    "\n",
    "\n",
    "            outcomes[i, k, :] = Y_test[:]\n",
    "            Y_train_knn = np.append(Y_train_knn, predictions_knn[i, k, :].reshape(1,-1), axis=0)\n",
    "            Y_train_ldmm = np.append(Y_train_ldmm, predictions_ldmm[i, k, :].reshape(1,-1), axis=0)\n",
    "            Y_train_same = np.append(Y_train_same, predictions_same[i, k, :].reshape(1,-1), axis=0)\n",
    "            Y_train_arima = np.append(Y_train_arima, predictions_arima[i, k, :].reshape(1,-1), axis=0)\n",
    "\n",
    "\n",
    "    new_loss_knn = np.mean((predictions_knn[:,-1]-outcomes[:,-1])**2/ outcomes[:,-1]**2, axis=0)\n",
    "    new_loss_ldmm = np.mean((predictions_ldmm[:,-1]-outcomes[:,-1])**2 / outcomes[:,-1]**2, axis=0)\n",
    "    new_loss_same = np.mean((predictions_same[:,-1]-outcomes[:,-1])**2 / outcomes[:,-1]**2, axis=0)\n",
    "    new_loss_arima = np.mean((predictions_arima[:,-1]-outcomes[:,-1])**2 / outcomes[:,-1]**2, axis=0)\n",
    "    #maybe it calculates incorrect\n",
    "    std_knn = np.sqrt(np.mean(((predictions_knn[:,-1]-outcomes[:,-1])**2/ outcomes[:,-1]**2 - new_loss_knn) ** 2, axis=0))\n",
    "    std_ldmm = np.sqrt(np.mean(((predictions_ldmm[:,-1]-outcomes[:,-1])**2/ outcomes[:,-1]**2 - new_loss_ldmm) ** 2, axis=0))\n",
    "    std_same = np.sqrt(np.mean(((predictions_same[:,-1]-outcomes[:,-1])**2/ outcomes[:,-1]**2 - new_loss_same) ** 2, axis=0))\n",
    "    std_arima = np.sqrt(np.mean(((predictions_arima[:,-1]-outcomes[:,-1])**2/ outcomes[:,-1]**2 - new_loss_arima) ** 2, axis=0))\n",
    "\n",
    "# parameters.append(params)\n",
    "# losses.append(np.mean(new_loss_ldmm))\n",
    "# clear_output(wait=True)\n",
    "# print(j, np.mean(new_loss_ldmm), params, new_loss_ldmm)\n",
    "# minset = np.argmin(losses)\n",
    "# print('minimum:', minset, losses[minset], parameters[minset])\n",
    "    print(lookfront)\n",
    "    print('knn', new_loss_knn[1:])\n",
    "    print('ldmm', new_loss_ldmm[1:])\n",
    "    print('same', new_loss_same[1:])\n",
    "    print('arima', new_loss_arima[1:])\n",
    "    print('knn', std_knn[1:])\n",
    "    print('ldmm', std_ldmm[1:])\n",
    "    print('same', std_same[1:])\n",
    "    print('arima', std_arima[1:])\n",
    "    print()\n",
    "#     for i in range(5):\n",
    "#         plt.plot(timestamps[-n_test:], predictions_ldmm[:, -1, i], 'b--', label='LDMM')\n",
    "#         plt.plot(timestamps[-n_test:], predictions_knn[:, -1, i], 'g--', label='kNN')\n",
    "#         plt.plot(timestamps[-n_test:], predictions_same[:, -1, i], 'y--', label='SAME')\n",
    "#         plt.plot(timestamps[-n_test:], predictions_arima[:, -1, i], 'r--', label='ARIMA')\n",
    "#         plt.plot(timestamps[-n_test:], data[-n_test:, i], 'k-', label='Test data')\n",
    "#         plt.legend(loc=3,fontsize='xx-small')\n",
    "#         plt.title(titles[i])\n",
    "#         plt.xlabel('Month')\n",
    "#         plt.ylabel('Value')\n",
    "#         plt.savefig(\"LDMM_ranepa_multivariate_lookfront=\"+str(lookfront)+str(i)+\".png\")\n",
    "#         plt.show()\n",
    "# losses_ldmm.append(new_loss_ldmm)\n",
    "# losses_knn.append(new_loss_knn)\n",
    "\n",
    "# #5 1000 10000 10000 плохо\n",
    "# 18521 0.004342346107326652 (17, 10000.0, 10000.0, 10000.0, 30) [0.01537566 0.0011506  0.00255974 0.00158956 0.00103616]\n",
    "# minimum: 9324 0.003404438586616477 (11, 10.0, 1000.0, 0.001, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
